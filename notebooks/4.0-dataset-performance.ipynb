{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d358e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iragca.matplotlib import Styles\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from lib.architectures import SimpleCNN\n",
    "from lib.config import Directories\n",
    "from lib.data import PlantDocDiseaseDetection, PlantVillageDiseaseDetection, PlantDocSymptomIdentification\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "plt.style.use(Styles.ML.value)\n",
    "\n",
    "model_name = \"disease_detection_model\"\n",
    "\n",
    "\n",
    "IMAGE_SIZE = (32, 32)\n",
    "transform_pipeline = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "KAGGLE_DATA_PATH = Directories.EXTERNAL_DATA_DIR.value / \"kagglehub\"\n",
    "\n",
    "plantvillage = PlantVillageDiseaseDetection(data_path=KAGGLE_DATA_PATH / \"plantvillage\", transforms=transform_pipeline)\n",
    "plantdoc = PlantDocDiseaseDetection(data_path=KAGGLE_DATA_PATH / \"plantdoc\", transforms=transform_pipeline)\n",
    "plantdoc_si = PlantDocSymptomIdentification(data_path=KAGGLE_DATA_PATH / \"plantdoc\", transforms=transform_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeb131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plantdoc_loader = DataLoader(plantdoc, batch_size=32, shuffle=True)\n",
    "plantvillage_loader = DataLoader(plantvillage, batch_size=32, shuffle=True)\n",
    "plantdoc_si_loader = DataLoader(plantdoc_si, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe5b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Dataset PlantDocDiseaseDetection: 100%|██████████| 92/92 [00:27<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8954\n",
      "Accuracy: 0.8392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(channels=3, output_dim=1)\n",
    "model.load_state_dict(torch.load(Directories.MODELS_DIR.value / f\"{model_name}.pth\"))\n",
    "\n",
    "\n",
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    THRESHOLD = 0.5\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=f\"Evaluating Dataset {data_loader.dataset.__class__.__name__}\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = (outputs >= THRESHOLD).long()\n",
    "\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return f1, accuracy\n",
    "\n",
    "f1, accuracy = test(model, plantdoc_loader)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30ccf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Dataset PlantVillageDiseaseDetection: 100%|██████████| 1698/1698 [00:39<00:00, 43.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8040\n",
      "Accuracy: 0.7608\n"
     ]
    }
   ],
   "source": [
    "f1, accuracy = test(model, plantvillage_loader)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e8fc95",
   "metadata": {},
   "source": [
    "## Symptom Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e34e00ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptom_identifier = SimpleCNN(channels=3, output_dim=12)\n",
    "symptom_identifier.load_state_dict(torch.load(Directories.MODELS_DIR.value / f\"symptom_identification_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4d27b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Dataset PlantDocSymptomIdentification: 100%|██████████| 66/66 [00:16<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    THRESHOLD = 0.5\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=f\"Evaluating Dataset {data_loader.dataset.__class__.__name__}\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "\n",
    "all_labels, all_preds = test(symptom_identifier, plantdoc_si_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "666414ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7692\n",
      "Accuracy: 0.7569\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf0bb741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       769\n",
      "           1       0.84      0.80      0.82       238\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.68      0.68      0.68       130\n",
      "           4       0.03      1.00      0.06         2\n",
      "           5       0.74      0.67      0.71        91\n",
      "           6       0.80      0.52      0.63        54\n",
      "           7       0.75      0.56      0.64        79\n",
      "           8       0.77      0.77      0.77       223\n",
      "           9       0.83      0.61      0.70        93\n",
      "          10       0.72      0.74      0.73       415\n",
      "          11       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76      2094\n",
      "   macro avg       0.58      0.60      0.55      2094\n",
      "weighted avg       0.79      0.76      0.77      2094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iragca/Documents/github/DS413-final-project/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/iragca/Documents/github/DS413-final-project/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/iragca/Documents/github/DS413-final-project/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
